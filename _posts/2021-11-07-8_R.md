---
layout: page
title: "8_R"
categories: researches
#permalink: /homeworks/researches/
---
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: [
      "MathMenu.js",
      "MathZoom.js",
      "AssistiveMML.js",
      "a11y/accessibility-menu.js"
    ],
    jax: ["input/TeX", "output/CommonHTML"],
    TeX: {
      extensions: [
        "AMSmath.js",
        "AMSsymbols.js",
        "noErrors.js",
        "noUndefined.js",
      ]
    }
  });
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<b>Do a research about the following topics:</b>

<b>- The law of large numbers LLN, the various definitions of convergence</b>

<b>- The convergence of the Binomial to the normal and Poisson distributions</b>

<b>- The central limit theorem \[in anticipation of a topic we will study later\] </b>

- The Law of Large Numbers

According to Wikipedia, “In probability theory, the law of large numbers (LLN) is a theorem that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials should be close to the expected value and will tend to become closer to the expected value as more trials are performed.”

There are two different forms of this law: the weak law of large numbers and the strong law of large numbers. This comes from the fact that there are different ways the average of a variable can converge.  These are

- Convergence in distribution
- Convergence in probability
- Almost sure convergence

A sequence \X_1, \X_2, ... of real-valued random variables is said to converge in distribution, or converge weakly, or converge in law to a random variable X if

![convergence_in_distribution](/images/8_A-convergence_in_distribution.png)
  
for every real number x at which F is continuous. Here Fn and F are the cumulative distribution functions of random variables Xn and X, respectively.

A sequence {Xn} of random variables converges in probability towards the random variable X if for all ε > 0

![convergence_in_probability](/images/8_A-convergence_in_probability.png)

To say that the sequence Xn converges almost surely or almost everywhere or with probability 1 or strongly towards X means that

![almost_sure_convergence](/images/8_A-almost_sure_convergence.png)

The weak law of large numbers states that the sample average converges in probability towards the expected value

![lln_weak](/images/8_A-lln_weak.png)

The strong law of large numbers states that the sample average converges almost surely to the expected value

![lln_strong](/images/8_A-lln_strong.png) 

- The convergence of the Binomial to the normal and Poisson distributions

The Poisson distribution with rate parameter r <- (0,∞] has probability density function g(n) = e^-r (r^n/n!)

The parameter r is both the mean and the variance of the distribution.

Suppose that p <- (0, 1) for n <- N+ and that np_n -> r <- (0, ∞) as n -> ∞. Then the binomial distribution with parameters n and p_n converges to the Poisson distribution with parameter r as n -> ∞.

Suppose that ( X1, X2, ...) is a sequence of independent, identically distributed, real-valued random variables (defined on the same probability space) with mean μ and standard deviation σ. Let Yn = ∑i =1 n Xi denote the sum of the first n variables. A weak version of the law of large numbers states that the distribution of the average Mn = 1/n Y n converges to the point mass distribution at μ as n → ∞. The convergence is also in probability. In fact the convergence is with probability 1 (much stronger), assuming that σ is finite. The central limit theorem states that the distribution of the standard score Zn = (Yn − n μ)/(√n σ) converges to the standard normal distribution as n → ∞

- The central limit theorem

The central limit theorem states that if you have a population with mean μ and standard deviation σ and take sufficiently large random samples from the population with replacement (Sampling ''with replacement'' means that when a unit selected at random from the population, it is returned to the population (replaced), and then a second element is selected at random), then the distribution of the sample means will be approximately normally distributed. This will hold true regardless of whether the source population is normal or skewed, provided the sample size is sufficiently large (usually n > 30). If the population is normal, then the theorem holds true even for samples smaller than 30. In fact, this also holds true even if the population is binomial, provided that min(np, n(1-p))> 5, where n is the sample size and p is the probability of success in the population.

----------------------------------------------------------------------------------

Sources:

https://en.wikipedia.org/wiki/Law_of_large_numbers

https://en.wikipedia.org/wiki/Convergence_of_random_variables

https://www.randomservices.org/random/bernoulli/Binomial.html

http://math.bme.hu/~nandori/Virtual_lab/stat/dist/Convergence.pdf

https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Probability/BS704_Probability12.html

