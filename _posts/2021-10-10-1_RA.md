---
layout: page
title: "3_R"
categories: researches
#permalink: /homeworks/researches/
---
<b>1_RA. Understand how the floating point representation works and describe systematically (possibly using categories) all the possible problems that can happen. Try to classify the various issues and limitations (representation, comparison, rounding, propagation, approximation, loss of significance, cancellation, etc.) and provide simple examples for each of the categories you have identified</b>

At the root of the problems regarding floating point representation there is the physical limitation on the representation of a number. To explain the implications, imagine how a value like 1/3 would be represented. For us humans, if we do 1/3 + 1/3 + 1/3 that gives us 3/3 = 1 and the calculation is correct. But calculators don’t see fraction the way humans see them, instead they use this so called floating point notation. The standard way a calculator represents numbers is by taking a 64-bit block (also said double precision floating point representation, while the original 32-bit representation is called single precision) and divide it in three parts: the first bit is the sign bit, the next 11 bits represent the exponent, while the last 52 bit represent the mantissa (also called significant). Written in base two, such a number would be something like, for example, 1.0110101 x 10^-101, and in memory this number would be written with a 0 as the sign bit, to mean that it is positive, then it would have the binary representation of the exponent and then it would have the mantissa, which is the part of the first number which is after the dot. The integer part before the dot is taken for granted.

To make an example, the decimal value 0.1 (or 1 x 10^-1) would be represented in base 2 as 0.000110011001100110011… (or 1 x 2^-4 + 1 x 2^-5 + 1 x 2^-8 + 1 x 2^-9 + 1 x 2^-12 + 1 x 2^-13 + …). Since the sequence of bits after the dot is infinite, his representation would truncate bits that are after a certain point. Not only that, but also the number would be approximated to the value closest to the one it’s trying to represent. At last, this explains why when we try, for example, to calculate 0.1 + 0.1 + 0.1 in Python, we get 0.30000000000000004 and not 0.3.

![python-floating-point](/images/1_RA-python-floating-point.png)

So there are different kinds of error that can occur because of the representation of floating point numbers. 

One example is rounding errors, and that is what has been mentioned just before.

Another type of error is comparison error, and again that can be deduced from what said before. Since the value 0.1 is not precisely represented, we would have 0.1 + 0.1 + 0.1 != 0.3 .

A third problem that can occur is error propagation. While in a single number the difference between the real number and its representation is very small, doing lots of operations like addition or subtraction can lead to an accumulation of those error that can add up to become larger and larger.



Sources:

https://floating-point-gui.de/basic/
https://indico.ictp.it/event/8344/session/50/contribution/207/material/slides/0.pdf
https://www.youtube.com/watch?v=PZRI1IfStY0

